<<<<<<< HEAD
#e"e$'f-#f 7???
rep_train_set <- train_set
for(i in 1:multiple_count)
rep_train_set <- rbind(rep_train_set, positive_train_set)
nrow(rep_train_set[rep_train_set$y==0,])/nrow(rep_train_set[rep_train_set$y==1,])
return (rep_train_set)
}
computeF1 <- function(bingos, recommend_number, actual_number){
precision <- bingos / recommend_number
recall <- bingos / actual_number
F1 <- 2 * precision * recall / (precision + recall)
message(bingos, ' ', recommend_number, ' ', precision, ' ', recall, ' ', F1)
return (list(precision, recall, F1))
}
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 5
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 473)
index_range <- c(62:65,66:69,300)#4:9, ,297:304  ,66:69  ,62:65  4:61  ,62:293
formula <- as.formula(paste("y ~ ", paste(colnames(train_set[index_range]),
collapse = " + ")))
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 473)
index_range <- c(62:65,66:69,304)#4:9, ,297:304  ,66:69  ,62:65  4:61  ,62:293
formula <- as.formula(paste("y ~ ", paste(colnames(train_set[index_range]),
collapse = " + ")))
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 473)
index_range <- c(4,7,62:65,66:69,304)#4:9, ,297:304  ,66:69  ,62:65  4:61  ,62:293
formula <- as.formula(paste("y ~ ", paste(colnames(train_set[index_range]),
collapse = " + ")))
#model(train_set, test_set)
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 5
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 473)
formula
index_range <- c(4,7,62:65,66:69,304,305)#4:9, ,297:304  ,66:69  ,62:65  4:61  ,62:293
formula <- as.formula(paste("y ~ ", paste(colnames(train_set[index_range]),
collapse = " + ")))
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 473)
setwd("E:\\Competetion\\TianChi\\alibaba_mobile_recommend_system\\Code\\DataProcess\\R")
train_set <- read.table('DataSet\\feature.csv', head = FALSE, sep = ',')
test_set <- read.table('DataSet\\test_set.csv', head = FALSE, sep = ',')
pre_recommend_set <- read.table('DataSet\\prepare_recommend_set.csv', head = FALSE, sep = ',')
colnames <- c('user_id', 'item_id', 'y', paste("vc", 1:(29*2), sep = ""), paste("rate", 1:(29*8), sep = ""), 'hour', 'category', 'user_geohash',
paste("u", 1:22, sep = ""), paste("i", 1:14, sep = ""))
colnames(train_set) <- colnames
colnames(test_set) <- colnames
colnames(pre_recommend_set) <- colnames
index_range <- c(4,7,62:65,66:69,304)#4:9, ,297:304  ,66:69  ,62:65  4:61  ,62:293
formula <- as.formula(paste("y ~ ", paste(colnames(train_set[index_range]),
collapse = " + ")))
formula
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 5
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 473)
computeF1(tp, tp + fp, 393)
setwd("E:\\Competetion\\TianChi\\alibaba_mobile_recommend_system\\Code\\DataProcess\\R")
train_set <- read.table('DataSet\\feature.csv', head = FALSE, sep = ',')
test_set <- read.table('DataSet\\test_set.csv', head = FALSE, sep = ',')
pre_recommend_set <- read.table('DataSet\\prepare_recommend_set.csv', head = FALSE, sep = ',')
=======
library(MASS)
Sigma<-matrix(c(10,3,3,2),2,2)
Sigma
mvrnorm(n=1000,rep(0,2),Sigma)
Sigma
help(mvrnorm)
my<-mvrnorm(n=1000,rep(0,2),Sigma)
plot(my)
library(mvtnorm)
install.packages("mvtnorm")
runif(5,0,1)
x=runif(100)
hist(x,prob=T,col=gray(.9),main="uniform on [0,1]")
curve(dunif(x,0,1),add=T)
x=rnorm(100)
hist(x,prob=T,main="normal mu=0,sigma=1")
curve(dnorm(x),add=T)
par(mfrow=c(1,3))
p=0.25
for( n in c(10,20,50))
{   x=rbinom(100,n,p)
hist(x,prob=T,main=paste("n =",n))
xvals=0:n
points(xvals,dbinom(xvals,n,p),type="h",lwd=3)
}
par(mfrow=c(1,1))
library(mvtnorm)
a <- seq(-10, 10)
b <- seq(-20, 20, 2)
mu <- cbind(a, b)
install.packages("mvtnorm")
library(mvtnorm)
mu
mvn_pdf <- dmvnorm(mu, mean = c(0, 0), sig = matrix( c(1, -0.5, -0.5, 1), 2,2))
install.packages("dmvnorm")
mean<-(mu*0)[,1]
sig <-matrix(c(1,-.5,-.5,1),ncol=2)
mean
sig
install.packages("mvtnorm")
runif(10,-0.1,0.1)
setwd("E:\\TianChi\\alibaba_mobile_recommend_system\\Code\\DataProcess\\R")
train_set <- read.table('DataSet\\feature.csv', head = FALSE, sep = ',')
test_set <- read.table('DataSet\\test_set.csv', head = FALSE, sep = ',')
<<<<<<< HEAD
=======
pre_recommend_set <- read.table('DataSet\\prepare_recommend_set.csv', head = FALSE, sep = ',')
>>>>>>> 972f41ad2af1fc238e65d04b58a152301666f6bf
base_train_set <- read.table('DataSet\\base_feature.csv', head = FALSE, sep = ',')
base_test_set <- read.table('DataSet\\base_test_set.csv', head = FALSE, sep = ',')
base_pre_recommend_set <- read.table('DataSet\\base_prepare_recommend_set.csv', head = FALSE, sep = ',')
>>>>>>> b119e2d23704d716051f55ae4014014a681c7188
colnames <- c('user_id', 'item_id', 'y', paste("vc", 1:(29*2), sep = ""), paste("rate", 1:(29*8), sep = ""), 'hour', 'category', 'user_geohash',
<<<<<<< HEAD
paste("u", 1:22, sep = ""), paste("i", 1:14, sep = ""))
=======
paste("u", 1:25, sep = ""), paste("i", 1:14, sep = ""))
>>>>>>> 972f41ad2af1fc238e65d04b58a152301666f6bf
colnames(train_set) <- colnames
colnames(test_set) <- colnames
colnames(pre_recommend_set) <- colnames
colnames <- c('user_id', 'item_id', paste("c", 1:(4*29), sep = ""), 'categoty', 'user_geohash', 'hour', 'y')
colnames(base_train_set) <- colnames
colnames(base_test_set) <- colnames
colnames(base_pre_recommend_set) <- colnames
<<<<<<< HEAD
index_range <- c(4,7,62:65,66:69,304)#4:9, ,297:304  ,66:69  ,62:65  4:61  ,62:293
formula <- as.formula(paste("y ~ ", paste(colnames(train_set[index_range]),
collapse = " + ")))
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 5
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 473)
computeF1(tp, tp + fp, 393)
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 4
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 6
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 7
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 6.5
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
table(base_train_set$y,base_train_set$c3)
table(base_train_set$y,base_train_set$c1)
table(base_train_set$y,base_train_set$c7)
table(base_train_set$y,base_train_set$c11)
table(base_train_set$y,base_train_set$c15)
table(base_train_set$y,base_train_set$c3)
table(base_train_set$y,base_train_set$c7)
table(base_train_set$y,base_train_set$c11)
table(base_train_set$y,base_train_set$c15)
table(train_set$y,train_set$vc1)
table(train_set$y,train_set$vc3)
table(train_set$y,train_set$vc2)
table(train_set$y,train_set$vc4)
table(train_set$y,train_set$rate1)
table(train_set$y,train_set$rate3)
table(train_set$y,train_set$rate2)
table(train_set$y,train_set$rate4)
computeF1(42,42+876,392)
index_range <- c(4,7)#4:9, ,297:304  ,66:69  ,62:65  4:61  ,62:293
formula <- as.formula(paste("y ~ ", paste(colnames(train_set[index_range]),
collapse = " + ")))
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 5
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=2,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
table(base_train_set$y,base_train_set$c3)
table(train_set$y,train_set$vc1)
table(train_set$y,train_set$vc2)
table(test_set$y,test_set$vc1)
table(test_set$y,test_set$vc2)
computeF1(9+19,9+19+499+424,393)
table(test_set$y,test_set$vc3)
table(test_set$y,test_set$vc4)
table(test_set$y,test_set$rate3)
table(test_set$y,test_set$rate7)
table(base_test_set$y,base_test_set$c3)
table(base_test_set$y,base_test_set$c7)
table(base_test_set$y,base_test_set$c1)
table(base_test_set$y,base_test_set$c2)
table(base_test_set$y,base_test_set$c3)
table(base_test_set$y,base_test_set$c4)
index_range <- c(62:65,66:69)#4:9, ,297:304  ,66:69  ,62:65  4:61  ,62:293
formula <- as.formula(paste("y ~ ", paste(colnames(train_set[index_range]),
collapse = " + ")))
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 5
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 4
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 6
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 7
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
#rf train and predict
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 10
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 8
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
dl_model <- dbn.dnn.train(as.matrix(expand_train_set[index_range]), as.matrix(as.numeric(expand_train_set$y) - 1),
hidden=c(100, 50, 100, 20, 10, 5, 5), cd = 1)
training_dnn <- nn.predict(dl_model, as.matrix(test_set[index_range]))
plot(training_dnn)
predictions_dnn <- nn.predict(dl_model, as.matrix(test_set[index_range]))
plot(predictions_dnn)
library(deepnet)
dl_model <- dbn.dnn.train(as.matrix(expand_train_set[index_range]), as.matrix(as.numeric(expand_train_set$y) - 1),
hidden=c(100, 50, 100, 20, 10, 5, 5), cd = 1)
training_dnn <- nn.predict(dl_model, as.matrix(test_set[index_range]))
predictions_dnn <- nn.predict(dl_model, as.matrix(test_set[index_range]))
plot(predictions_dnn)
length(which(predictions_dnn>0.35))
predictions_dnn[predictions_dnn > 0.35] <- 1
predictions_dnn[predictions_dnn <= 0.35] <- 0
table(test_set$y, predictions_dnn)
computeF1(21,555,393)
index_range <- c(62:65,66:69,304)#4:9, ,297:304  ,66:69  ,62:65  4:61  ,62:293
formula <- as.formula(paste("y ~ ", paste(colnames(train_set[index_range]),
collapse = " + ")))
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 6
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
index_range <- c(62:65,66:69)#4:9, ,297:304  ,66:69  ,62:65  4:61  ,62:293
formula <- as.formula(paste("y ~ ", paste(colnames(train_set[index_range]),
collapse = " + ")))
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 6
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
formula
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 6
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
computeF1(21,393,393)
auc(test_set$y,test_set$rate1)
auc(test_set$y,test_set$rate2)
auc(test_set$y,test_set$rate3)
auc(test_set$y,test_set$rate4)
auc(test_set$y,test_set$rate5)
auc(test_set$y,test_set$rate6)
auc(test_set$y,test_set$rate7)
auc(test_set$y,test_set$rate8)
auc(test_set$y,test_set$rate9)
auc(test_set$y,test_set$rate10)
auc(test_set$y,test_set$rate11)
auc(test_set$y,test_set$rate12)
auc(test_set$y,test_set$rate14)
auc(test_set$y,test_set$rate13)
auc(test_set$y,test_set$rate15)
auc(test_set$y,test_set$rate16)
auc(test_set$y,test_set$rate14)
auc(test_set$y,test_set$vc1)
auc(test_set$y,test_set$vc2)
auc(test_set$y,test_set$vc3)
auc(test_set$y,test_set$vc4)
auc(train_set$y,train_set$vc1)
auc(train_set$y,train_set$vc2)
auc(train_set$y,train_set$vc3)
auc(train_set$y,train_set$vc4)
index_range <- c(62:65,66:69,70:73)#4:9, ,297:304  ,66:69  ,62:65  4:61  ,62:293
formula <- as.formula(paste("y ~ ", paste(colnames(train_set[index_range]),
collapse = " + ")))
#model(train_set, test_set)
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 6
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
index_range <- c(62:65,66:69)#4:9, ,297:304  ,66:69  ,62:65  4:61  ,62:293
formula <- as.formula(paste("y ~ ", paste(colnames(train_set[index_range]),
collapse = " + ")))
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 5
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 6
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
table(base_test_set$y,base_test_set$c3)
table(base_test_set$y,base_test_set$c7)
table(base_test_set$y,base_test_set$c1)
table(base_train_set$y,base_train_set$c1)
table(base_train_set$y,base_train_set$c3)
table(base_train_set$y,base_train_set$c1!=0)
table(base_train_set$y,base_train_set$c3!=0)
table(base_test_set$y,base_test_set$c1!=0)
table(base_test_set$y,base_test_set$c3!=0)
dat1<-base_test_set[base_test_set$y==1&base_test_set$c3!=0,]
nrow(dat1)
table(dat1$y,dat1$time)
table(dat1$y,dat1$hour)
dat.1<-base_train_set[base_train_set$y==1&base_train_set$c3!=0,]
table(dat.1$y,dat.1$hour)
dat.1<-base_train_set[base_train_set$c3!=0,]
table(dat.1$y,dat.1$hour)
dat1<-base_test_set[base_test_set$c3!=0,]
table(dat1$y,dat1$hour)
table(dat1$y,dat1$hour>=19)
table(dat.1$y,dat.1$hour>=19)
computeF1(21,562,392)
computeF1(21,471,393)
table(dat1$y,dat1$hour/2)
table(dat1$y,dat1$floor(hour/2)
)
table(dat1$y,floor(dat1$hour/2))
table(dat.1$y,floor(dat.1$hour/2))
train_set <- read.table('DataSet\\feature.csv', head = FALSE, sep = ',')
test_set <- read.table('DataSet\\test_set.csv', head = FALSE, sep = ',')
pre_recommend_set <- read.table('DataSet\\prepare_recommend_set.csv', head = FALSE, sep = ',')
base_train_set <- read.table('DataSet\\base_feature.csv', head = FALSE, sep = ',')
base_test_set <- read.table('DataSet\\base_test_set.csv', head = FALSE, sep = ',')
base_pre_recommend_set <- read.table('DataSet\\base_prepare_recommend_set.csv', head = FALSE, sep = ',')
colnames <- c('user_id', 'item_id', 'y', paste("vc", 1:(29*2), sep = ""), paste("rate", 1:(29*8), sep = ""), 'hour', 'category', 'user_geohash',
paste("u", 1:22, sep = ""), paste("i", 1:14, sep = ""))
colnames(train_set) <- colnames
colnames(test_set) <- colnames
<<<<<<< HEAD
=======
colnames(pre_recommend_set) <- colnames
colnames <- c('user_id', 'item_id', paste("c", 1:(4*29), sep = ""), 'categoty', 'user_geohash', 'hour', 'y')
colnames(base_train_set) <- colnames
colnames(base_test_set) <- colnames
colnames(base_pre_recommend_set) <- colnames
index_range <- c(62:65,66:69)#4:9, ,297:304  ,66:69  ,62:65  4:61  ,62:293
formula <- as.formula(paste("y ~ ", paste(colnames(train_set[index_range]),
collapse = " + ")))
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 6
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
train_set <- read.table('DataSet\\new\\feature.csv', head = FALSE, sep = ',')
test_set <- read.table('DataSet\\new\\test_set.csv', head = FALSE, sep = ',')
pre_recommend_set <- read.table('DataSet\\new\\prepare_recommend_set.csv', head = FALSE, sep = ',')
base_train_set <- read.table('DataSet\\new\\base_feature.csv', head = FALSE, sep = ',')
base_test_set <- read.table('DataSet\\new\\base_test_set.csv', head = FALSE, sep = ',')
base_pre_recommend_set <- read.table('DataSet\\new\\base_prepare_recommend_set.csv', head = FALSE, sep = ',')
colnames <- c('user_id', 'item_id', 'y', paste("vc", 1:(29*2), sep = ""), paste("rate", 1:(29*8), sep = ""), 'hour', 'category', 'user_geohash',
paste("u", 1:22, sep = ""), paste("i", 1:14, sep = ""))
colnames(train_set) <- colnames
colnames(test_set) <- colnames
colnames(pre_recommend_set) <- colnames
colnames <- c('user_id', 'item_id', paste("c", 1:(4*29), sep = ""), 'categoty', 'user_geohash', 'hour', 'y')
colnames(base_train_set) <- colnames
colnames(base_test_set) <- colnames
colnames(base_pre_recommend_set) <- colnames
index_range <- c(62:65,66:69)#4:9, ,297:304  ,66:69  ,62:65  4:61  ,62:293
formula <- as.formula(paste("y ~ ", paste(colnames(train_set[index_range]),
collapse = " + ")))
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 6
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
rf_model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions_rf)-1)
table(test_set$y, predictions_rf)
tp<-length(intersect(which(predictions_rf==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions_rf==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
cnt <- nrow(test_set[test_set$y==0,]) / 5 / nrow(test_set[test_set$y==1,])
expand_test_set <- increasePositiveSample(test_set, cnt)
expand_test_set$y <- as.factor(expand_test_set$y)
message('positive/negative sample ratio: ', nrow(expand_test_set[expand_test_set$y==0,])/nrow(expand_test_set[expand_test_set$y==1,]))
rf_model <- randomForest(formula, expand_test_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = pre_recommend_set[index_range], type = "response")
pre_recommend_set$y<-predictions_rf
write.table(pre_recommend_set[pre_recommend_set$y==1,][1:2], file = 'Recommend\\user_item_based_recommend.csv', sep = ',')
cnt <- nrow(test_set[test_set$y==0,]) / 6 / nrow(test_set[test_set$y==1,])
expand_test_set <- increasePositiveSample(test_set, cnt)
expand_test_set$y <- as.factor(expand_test_set$y)
message('positive/negative sample ratio: ', nrow(expand_test_set[expand_test_set$y==0,])/nrow(expand_test_set[expand_test_set$y==1,]))
rf_model <- randomForest(formula, expand_test_set, ntree=2000,mtry=3,type="classification")
predictions_rf <- predict(rf_model, newdata = pre_recommend_set[index_range], type = "response")
pre_recommend_set$y<-predictions_rf
write.table(pre_recommend_set[pre_recommend_set$y==1,][1:2], file = 'Recommend\\user_item_based_recommend.csv', sep = ',')
=======
>>>>>>> b119e2d23704d716051f55ae4014014a681c7188
computeF1 <- function(bingos, recommend_number, actual_number){
precision <- bingos / recommend_number
recall <- bingos / actual_number
F1 <- 2 * precision * recall / (precision + recall)
message(bingos, ' ', recommend_number, ' ', precision, ' ', recall, ' ', F1)
return (list(precision, recall, F1))
}
increasePositiveSample <- function(data_set, multiple_count){
positive_data_set<-subset(data_set,data_set$y==1)
negative_data_set<-subset(data_set,data_set$y==0)
nrow(positive_data_set)
nrow(negative_data_set)
#e"e$'f-#f 7???
rep_data_set <- data_set
for(i in 1:multiple_count)
rep_data_set <- rbind(rep_data_set, positive_data_set)
nrow(rep_data_set[rep_data_set$y==0,])/nrow(rep_data_set[rep_data_set$y==1,])
return (rep_data_set)
}
index_range <- c(62:65,66:69)#4:9, ,297:304  ,66:69  ,62:65  4:61  ,62:293
formula <- as.formula(paste("y ~ ", paste(colnames(train_set[index_range]),
collapse = " + ")))
formula
library(pROC)
library(randomForest)
model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
cnt <- nrow(train_set[train_set$y==0,]) / nrow(train_set[train_set$y==1,]) / 6
expand_train_set <- increasePositiveSample(train_set, cnt)
expand_train_set$y <- as.factor(expand_train_set$y)
message('positive/negative sample ratio: ', nrow(expand_train_set[expand_train_set$y==0,])/nrow(expand_train_set[expand_train_set$y==1,]))#1.5
model <- randomForest(formula, expand_train_set, ntree=2000,mtry=3,type="classification")
predictions <- predict(model, newdata = test_set[index_range], type = "response")
roc(test_set$y, as.numeric(predictions)-1)
table(test_set$y, predictions)
tp<-length(intersect(which(predictions==1), which(test_set$y==1)))
fp<-length(intersect(which(predictions==1), which(test_set$y==0)))
computeF1(tp, tp + fp, 393)
<<<<<<< HEAD
computeF1(tp, tp + fp, 473)
=======
nrow(pre_recommend_set[pre_recommend_set$rate3!=0,])
nrow(pre_recommend_set[pre_recommend_set$rate3==0,])
summary(pre_recommend_set[,64])
summary(pre_recommend_set[,65])
table(test_set$y,test_set$rate3!=0,)
table(test_set$y,test_set$rate3!=0)
table(test_set$y,test_set$vc1)
table(train_set$y,train_set$vc1)
>>>>>>> 972f41ad2af1fc238e65d04b58a152301666f6bf
>>>>>>> b119e2d23704d716051f55ae4014014a681c7188
